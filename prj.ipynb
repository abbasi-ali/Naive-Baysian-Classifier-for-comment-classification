{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6W-2EvmABuQV"
   },
   "source": [
    "I used stemming in this project since stemming get rid of the suffixes and prefixes while at the same time, it preserves the positivity and negativity of the verb which can conveys critical information regarding the semantic of the sentence. Moreover, the title and the comment sections are merged together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-H_OW80CIE9"
   },
   "source": [
    "posterior = posterior of a sentence can be calucated by the given formula in the discription. However, posterior of a word means : (number of the word 'x in c class / total number of the word 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcsgXmzOCwp9"
   },
   "source": [
    "likelihood = number of the word x in c class / total number of the words in c class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1a2QEYsMDK-S"
   },
   "source": [
    "prior = number of the words in c class / total number of the words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xu1sa5FGDS23"
   },
   "source": [
    "evidence = number of the word 'x' / total number of the words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkJypFyODi7g"
   },
   "source": [
    "if 'digikala' exists in a class and not in the other, it will couse the posterior probability to be 0 in the class that it does not exist in since the likelihood would be 0 therefore the model can classify with false certainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Dam5RwkD_Rg"
   },
   "source": [
    "In order to calculate the likelihood, additive smoothing changes the formula from X / N to (x + alpha) / (N + alpha*d). In this formula, alpha is a hyper parameter, N is the total number of words in a class, and d is the number of the distict words in the said class. By using the additive smoothing, the likelihood term would always be greater than zero therefore it will prevent the posterior probability to become zero and lose the valuable information regarding other words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dbhx-xcKFhyR"
   },
   "source": [
    "for rare cancer datamodeling, false-negatives are extremely important therefore recall is a critical factor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehkpy-6mGQ2S"
   },
   "source": [
    "for youtube recommendation false negatives are not that important therefore precision is a better criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vEszG-QGmOk"
   },
   "source": [
    "F1 score is the harmonic mean between the precisio and the recall of a model. It combines the imformation in the precision and in the recall criteria. It provides a balance between these two method. It is used when we need this balance and the dataset is not even. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rr71Q7CfJUhz"
   },
   "source": [
    "![result.PNG](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GcEzwWLJfII"
   },
   "source": [
    "Regarding the F1 and accuracy scores, additive+preprocess mode yeilds the best result. Additive smoothing is much more effective than preprocessing. preprocessing does not seem to have significant effect in the result. However, removing additvie smoothing couses the recall to be 99 percent which means that the recommended class has more of the unique words than the not_recommended one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb_YrkQeb8cG"
   },
   "source": [
    "I suppose that negative verbs in conjunction with positive adjectives are most likely to cause error in the classification. If there woulb be an method to detect role of the words in a sentence then we could assign weights to verbs and adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "zRdHLB0AakFM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "Cj5cW9ble3_2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from __future__ import unicode_literals\n",
    "from hazm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "47pKlLAY3LEa"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Naive_baise:\n",
    "  def __init__(self, stop_words):\n",
    "    self.norm = Normalizer()\n",
    "    self.stemer =Stemmer()\n",
    "\n",
    "    self.rec_dict = {}\n",
    "    self.nrec_dict = {}\n",
    "\n",
    "    self.rec_cnt = 0\n",
    "    self.nrec_cnt = 0\n",
    "\n",
    "    self.stop_words = stop_words \n",
    "    self.false_preds = []\n",
    "\n",
    "\n",
    "  def fit_model(self, data_add, preprocess):\n",
    "    comment_df = pd.read_csv(data_add)\n",
    "\n",
    "    for ind, row in comment_df.iterrows():\n",
    "      rec = 1 if row['recommend'] == 'recommended' else 0 \n",
    "\n",
    "      cmt = row['comment'] + row['title']\n",
    "      cmt = self.norm.normalize(cmt)\n",
    "      sents = sent_tokenize(cmt)\n",
    "\n",
    "      for s in sents:\n",
    "        words = word_tokenize(s)\n",
    "\n",
    "        for w in words:\n",
    "          if preprocess == True:\n",
    "            if w in self.stop_words:\n",
    "              continue\n",
    "            \n",
    "            w = self.stemer.stem(w)\n",
    "\n",
    "          if rec == 1:\n",
    "            self.rec_cnt += 1\n",
    "            if w in self.rec_dict:\n",
    "              self.rec_dict[w] += 1\n",
    "            else:\n",
    "              self.rec_dict[w] = 1\n",
    "            \n",
    "          elif rec == 0:\n",
    "            self.nrec_cnt += 1\n",
    "            if w in self.nrec_dict:\n",
    "              self.nrec_dict[w] += 1\n",
    "            else:\n",
    "              self.nrec_dict[w] = 1\n",
    "    \n",
    "\n",
    "  def test_model(self, test_add, alpha, preprocess):\n",
    "    test_df = pd.read_csv(test_add)\n",
    "    true_pred = 0\n",
    "    false_pred = 0 \n",
    "    true_negative = 0\n",
    "    true_positive = 0\n",
    "\n",
    "    false_negative = 0\n",
    "    false_positive = 0\n",
    "\n",
    "    for ind, row in test_df.iterrows():\n",
    "      cmt = row['comment'] + row['title']\n",
    "      cmt = self.norm.normalize(cmt)\n",
    "      sents = sent_tokenize(cmt)\n",
    "      sent_set = set([])\n",
    "\n",
    "      for s in sents:\n",
    "        words = word_tokenize(s)\n",
    "\n",
    "        for w in words:\n",
    "          if preprocess == True:\n",
    "            if w in self.stop_words:\n",
    "              continue \n",
    "\n",
    "            w = self.stemer.stem(w)\n",
    "\n",
    "          sent_set.add(w)\n",
    "\n",
    "      p_1 = float((rec_cnt)/(rec_cnt + nrec_cnt))\n",
    "      p_0 = float((nrec_cnt)/(rec_cnt + nrec_cnt))\n",
    "\n",
    "      for w in sent_set:\n",
    "\n",
    "        if w in self.rec_dict:\n",
    "          p_w1 = float((self.rec_dict[w] + alpha)/(self.rec_cnt + alpha*len(self.rec_dict)))\n",
    "        else:\n",
    "          p_w1 = float(alpha / (self.rec_cnt + alpha*len(self.rec_dict)))\n",
    "\n",
    "        if w in self.nrec_dict:\n",
    "          p_w0 = float((self.nrec_dict[w] + alpha)/(self.nrec_cnt + alpha*len(self.nrec_dict)))\n",
    "        else:\n",
    "          p_w0 = float(alpha / (self.nrec_cnt + alpha*len(self.nrec_dict)))\n",
    "\n",
    "        p_1 *= p_w1\n",
    "        p_0 *= p_w0\n",
    "\n",
    "      if p_1 >= p_0:\n",
    "        pred = 'recommended'\n",
    "      else:\n",
    "        pred = 'not_recommended'\n",
    "\n",
    "      if pred == row['recommend']:\n",
    "        true_pred += 1\n",
    "      else:\n",
    "        self.false_preds.append(row['comment'])\n",
    "        false_pred += 1\n",
    "\n",
    "      if pred == 'recommended' and row['recommend'] == 'recommended':\n",
    "        true_positive += 1\n",
    "\n",
    "      if pred == 'recommended' and row['recommend'] == 'not_recommended':\n",
    "        false_positive += 1\n",
    "\n",
    "      if pred == 'not_recommended' and row['recommend'] == 'recommended':\n",
    "        false_negative += 1\n",
    "      \n",
    "      if pred == 'not_recommended' and row['recommend'] == 'not_recommended':\n",
    "        true_negative += 1\n",
    "\n",
    "    N = len(test_df)\n",
    "    accu = float(true_pred / N) * 100 \n",
    "    preci = float(true_positive / (true_positive + false_positive)) * 100 \n",
    "    reca = float(true_positive / (true_positive + false_negative)) * 100 \n",
    "    F1 = 2*float((preci * reca)/(preci + reca)) \n",
    "\n",
    "    print('accuracy:{} F1:{}'.format(accu, F1))\n",
    "    print('precision:{} recall:{}'.format(preci, reca))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUeoGgCDD7M8",
    "outputId": "9154f84b-0217-45ef-950a-aaa20fea3bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:93.75 F1:93.82716049382717\n",
      "precision:92.6829268292683 recall:95.0\n",
      "سلام ، راحت شدم از کابل شارژ ، توصیه میشود به شدت . ارزان گوشی خود را به شارژ وایرلس مجهز کنید .\n",
      "فندک قبلیم مدام فیوز میسوزوند و یک بار شارژر موبایل هم سوزوند ولی با این هیچ مشکلی بوجود نیومده تا الان. کیفیتش خیلی خوبه و لامپ هم داره\n",
      "، دوستان عزیز دقت کنند در مورد خرید این پاوربانک خیلی مهمه چون من خریدم دوبار خرید زدم و دقت کن از سری a و سری b خیلی تفاوت ها با همدیگه دارند یکی از مهمترین تفاوت هایی که دارند اینه که سری b سه تا خروجی ۶ آمپر داره اما خروجی های سری ایدم پرو یک آمپر هستش خیلی دقت کنید من خرید زدم بعدش که آوردم باز کردم می بینم که اون چیزی که سفارش دادم نیستش بعد پولتونو که بخواهیم پس بگیرین حدود ۲۰ روز طول میکشه هفت روز طول میکشه که این جعبه رو واستون برگردوند و بعدش ۷ روز طول میکشه که حدود اینکه پولتونو بهتون بدن خریدی که من زدم نه تنها مغایرت داشت بلکه خود دستگاه هم خراب بود  حتی شارژ نمی‌کرد میزاری داخل شارژ به سرعت شارژش تموم میشد و تمام چراغ هاشم خراب بود خودش شارژرش هم مشکل داشت راه خود شارژ خاموش نمی شد متاسفانه من اصلا راضی نیستم و پیشنهاد می کنم به هیچ عنوان این پاور بانک را نگیر این یاد میگیرین از جایی تهیه کنید که ببینید پشت سری بی هک شده باشه خیلی مهمه که ۶ آمپر باشد تا اینکه ۲ آمپر شدت خروجی  اصلا قابل مقایسه نیست\n",
      "من خودم جزو افرادی بودم که نزدیک سیزده ساله از انواع فیلتر سرکان اعم از روغن، هوا و اتاق استفاده میکردم ولی به تازگی متوجه و اطلاع یافتم که فیلتر گاج باکیفیت تر از فیلتر سرکان می‌باشد و هم چنین قیمت بمراتب مناسب تربت نسبت به سرکان دارد و طرف فروشنده که داشت روغن فیلترش را به من می‌فروخت. واقعا بهم اثبات کرد که گاج باکیفیت تر از سرکان می‌باشد.\n",
      "سلام دوستان بعد از استفاده چراغ چک تویوتا کمری ۲۰۰۷ خاموش شد\n"
     ]
    }
   ],
   "source": [
    "stop_words = '. ، ! و : ؛ من تو او ما شما اونا آنها به از در با حتی اگر اگه اما ولی بود هست شد ه ها های اون که'.split(' ')\n",
    "nb = Naive_baise(stop_words)\n",
    "\n",
    "nb.fit_model('comment_train.csv', True)\n",
    "nb.test_model('comment_test.csv', 0.01, True)\n",
    "falses = [nb.false_preds[i] for i in range(5)]\n",
    "\n",
    "for cm in falses:\n",
    "  print(cm)\n",
    "\n",
    "      \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled34.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
